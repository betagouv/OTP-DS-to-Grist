# ü¶Ñ One Trick Pony DS to Grist - Documentation Technique

## Vue d'ensemble du projet

**One Trick Pony DS to Grist** est une application Flask de synchronisation automatis√©e entre l'API D√©marches Simplifi√©es (DS) et Grist. Le syst√®me r√©cup√®re les donn√©es de d√©marches administratives fran√ßaises via GraphQL et les structure automatiquement dans des tableaux Grist.

### Architecture g√©n√©rale

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Interface Web  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Application     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ     API DS       ‚îÇ
‚îÇ    Flask/DSFR    ‚îÇ     ‚îÇ     Flask        ‚îÇ     ‚îÇ    (GraphQL)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ                            
                               ‚ñº                            
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               
                        ‚îÇ   Processeur     ‚îÇ               
                        ‚îÇ     Python       ‚îÇ               
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               
                               ‚îÇ                            
                               ‚ñº                            
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               
                        ‚îÇ    API Grist     ‚îÇ               
                        ‚îÇ   (REST API)     ‚îÇ               
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               
```

---

## üìÅ Structure des fichiers du projet

### **Fichiers principaux de l'application**

1. **`app.py`** - Application Flask principale avec interface web
2. **`grist_processor_working_all.py`** - Processeur principal de synchronisation DS ‚Üí Grist
3. **`requirements.txt`** - D√©pendances Python du projet

### **Modules de requ√™tes API**

4. **`queries.py`** - Module principal d'orchestration des requ√™tes
5. **`queries_config.py`** - Configuration des connexions API
6. **`queries_graphql.py`** - Requ√™tes GraphQL vers l'API DS
7. **`queries_extract.py`** - Extraction et transformation des donn√©es
8. **`queries_util.py`** - Utilitaires pour le traitement des donn√©es

### **Modules sp√©cialis√©s**

9. **`repetable_processor.py`** - Traitement des blocs r√©p√©tables
10. **`schema_utils.py`** - Gestion des sch√©mas de d√©marches

### **Templates HTML**

11. **`templates/base.html`** - Template de base DSFR
12. **`templates/index.html`** - Page de configuration
13. **`templates/execution.html`** - Page d'ex√©cution et monitoring
14. **`templates/debug.html`** - Page de d√©bogage

---

## üèóÔ∏è Architecture d√©taill√©e des composants

### **Diagramme de flux de donn√©es**

```
[Interface Web Flask]
        ‚Üì
[Configuration Manager] ‚Üí [.env file]
        ‚Üì
[Task Manager] ‚Üí [Thread Pool]
        ‚Üì
[Subprocess: grist_processor]
        ‚Üì
[GraphQL Client] ‚Üí [API DS]
        ‚Üì
[Data Transformer]
        ‚Üì
[Type Detector]
        ‚Üì
[Grist Client] ‚Üí [API Grist]
        ‚Üì
[WebSocket Updates] ‚Üí [Interface Web]
```

### **Communication inter-composants**

1. **Flask ‚Üî Processeur Python:**
   - Via subprocess avec environnement isol√©
   - Communication par stdout/stderr
   - Parsing des logs pour progression

2. **Flask ‚Üî Interface Web:**
   - HTTP REST pour les donn√©es
   - WebSocket pour temps r√©el
   - JSON pour tous les √©changes

3. **Processeur ‚Üî APIs externes:**
   - HTTPS avec authentification Bearer
   - Retry avec backoff exponentiel
   - Timeout configurables

---

## üîÑ Flux de traitement d√©taill√©

### **Phase 1 : Initialisation et configuration**

1. **Chargement de l'environnement :**
   - `load_dotenv()` charge le fichier `.env`
   - Variables mapp√©es : `DEMARCHES_API_TOKEN`, `GRIST_API_KEY`, etc.
   - Validation des param√®tres requis

2. **Test de configuration :**
   - Requ√™te GraphQL minimale vers DS
   - GET sur `/docs/{doc_id}` pour Grist
   - V√©rification des permissions

### **Phase 2 : R√©cup√©ration des donn√©es DS**

1. **R√©cup√©ration de la d√©marche :**
   ```python
   demarche_data = get_demarche(demarche_number)
   ```
   - Requ√™te GraphQL avec fragments
   - R√©cup√®re m√©tadonn√©es et liste des dossiers
   - Pagination automatique si > 100

2. **Application des filtres (si configur√©s) :**
   - Conversion des filtres UI en format API
   - `DATE_DEPOT_DEBUT` ‚Üí `createdSince` (ISO 8601)
   - `STATUTS_DOSSIERS` ‚Üí `states` (array)
   - Utilisation de `get_demarche_dossiers_filtered()`

3. **R√©cup√©ration d√©taill√©e par batch :**
   ```python
   for batch in batches:
       for dossier_number in batch:
           dossier = get_dossier(dossier_number)
   ```
   - Division en lots de 25-100 dossiers
   - Requ√™tes parall√®les si activ√©
   - Gestion des timeouts et retry

### **Phase 3 : D√©tection et cr√©ation de structure**

1. **M√©thode avanc√©e (schema_utils) :**
   ```python
   schema = get_demarche_schema(demarche_number)
   columns = create_columns_from_schema(schema)
   ```
   - R√©cup√®re les descripteurs sans donn√©es
   - G√©n√®re la structure compl√®te
   - Plus rapide et plus fiable

2. **M√©thode classique (√©chantillonnage) :**
   ```python
   columns = detect_column_types(sample_dossiers, problematic_ids)
   ```
   - Analyse 3 dossiers √©chantillons
   - D√©tecte les types par inspection
   - Fallback si schema_utils √©choue

3. **Cr√©ation des tables Grist :**
   - Table `dossiers` : M√©tadonn√©es principales
   - Table `champs` : Valeurs des champs
   - Table `annotations` : Notes des instructeurs
   - Table `repetable_rows` : Blocs r√©p√©tables (si d√©tect√©s)

### **Phase 4 : Transformation et insertion**

1. **Transformation des donn√©es :**
   ```python
   flat_data = dossier_to_flat_data(dossier, problematic_ids)
   ```
   - S√©pare en 4 structures distinctes
   - Normalise les noms de colonnes
   - Convertit les types de donn√©es

2. **Insertion optimis√©e :**
   - Skip des dossiers d√©j√† trait√©s
   - Insertion par batch de 100-500 records
   - Parall√©lisation avec ThreadPoolExecutor
   - Retry automatique en cas d'√©chec

3. **Gestion des cas sp√©ciaux :**
   - **Blocs r√©p√©tables :** Table s√©par√©e avec index
   - **Champs g√©ographiques :** GeoJSON en texte
   - **Fichiers :** URLs et m√©tadonn√©es
   - **Labels :** JSON array en texte

### **Phase 5 : Monitoring et reporting**

1. **Logs en temps r√©el :**
   - WebSocket pour mises √† jour instantan√©es
   - Buffer de 1000 lignes maximum
   - Horodatage de chaque message

2. **Indicateurs de progression :**
   - Pourcentage global
   - Nombre de dossiers trait√©s
   - Temps √©coul√©/restant estim√©

3. **Rapport final :**
   - Total succ√®s/√©checs
   - Dur√©e totale
   - Erreurs d√©taill√©es si pr√©sentes

---

## üìä Structure des donn√©es

### **Table `dossiers`**

| Colonne | Type | Description |
|---------|------|-------------|
| dossier_id | Text | ID unique GraphQL |
| number | Int | Num√©ro du dossier |
| state | Text | √âtat (en_construction, etc.) |
| date_depot | DateTime | Date de d√©p√¥t |
| date_derniere_modification | DateTime | Derni√®re modification |
| date_traitement | DateTime | Date de traitement |
| demandeur_type | Text | PersonnePhysique/Morale |
| demandeur_nom | Text | Nom du demandeur |
| demandeur_prenom | Text | Pr√©nom |
| demandeur_email | Text | Email |
| demandeur_siret | Text | SIRET entreprise |
| entreprise_raison_sociale | Text | Raison sociale |
| groupe_instructeur_label | Text | Nom du groupe |
| supprime_par_usager | Bool | Dossier supprim√© |
| labels_json | Text | Labels en JSON |

### **Table `champs`**

| Colonne | Type | Description |
|---------|------|-------------|
| dossier_number | Int | R√©f√©rence au dossier |
| champ_id | Text | ID du descripteur |
| [colonnes dynamiques] | Variable | Une colonne par champ d√©tect√© |

### **Table `annotations`**

| Colonne | Type | Description |
|---------|------|-------------|
| dossier_number | Int | R√©f√©rence au dossier |
| [colonnes dynamiques] | Variable | Une colonne par annotation |

### **Table `repetable_rows`**

| Colonne | Type | Description |
|---------|------|-------------|
| dossier_number | Int | R√©f√©rence au dossier |
| block_label | Text | Nom du bloc r√©p√©table |
| block_row_index | Int | Index de la ligne (0, 1, 2...) |
| block_row_id | Text | ID unique de la ligne |
| [colonnes dynamiques] | Variable | Champs du bloc |

---

## üõ†Ô∏è M√©canismes d'optimisation

### **1. Cache de colonnes**

```python
class ColumnCache:
    def __init__(self, client):
        self.columns_cache = {}  # {table_id: {column_id: column_type}}
```

- √âvite les requ√™tes r√©p√©t√©es √† l'API Grist
- Rafra√Æchissement forc√© disponible
- R√©duit la latence de 50-70%

### **2. D√©tection incr√©mentale**

```python
existing_numbers = client.get_existing_dossier_numbers("dossiers")
new_dossiers = [d for d in dossiers if d["number"] not in existing_numbers]
```

- R√©cup√®re les dossiers d√©j√† trait√©s
- Skip automatique des doublons
- Permet les reprises apr√®s interruption

### **3. Traitement par lots (batching)**

```python
for i in range(0, len(dossiers), batch_size):
    batch = dossiers[i:i+batch_size]
    process_batch(batch)
```

- R√©duit le nombre d'appels API
- Optimise l'utilisation m√©moire
- Configurable via `BATCH_SIZE`

### **4. Parall√©lisation ThreadPool**

```python
with ThreadPoolExecutor(max_workers=max_workers) as executor:
    futures = [executor.submit(process_dossier, d) for d in batch]
    results = [f.result() for f in as_completed(futures)]
```

- Traitement concurrent des dossiers
- Configurable via `MAX_WORKERS`
- Am√©lioration 2-3x des performances

### **5. Filtrage c√¥t√© serveur**

```python
filters = {
    "createdSince": "2024-01-01T00:00:00Z",
    "states": ["en_instruction", "accepte"]
}
```

- R√©duit le volume de donn√©es transf√©r√©es
- Filtre directement dans GraphQL
- √âconomise bande passante et temps

### **6. Gestion d'erreurs granulaire**

```python
for dossier in batch:
    try:
        process_dossier(dossier)
        success_count += 1
    except Exception as e:
        log_error(f"Dossier {dossier['number']}: {e}")
        failed_dossiers.add(dossier['number'])
        continue
```

- Continue m√™me si un dossier √©choue
- Tracking d√©taill√© des √©checs
- Permet le retraitement cibl√©

